# -*- coding: utf-8 -*-
"""Projet-final-Mouille-Roussel-Charlet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xl5epaVaLtTD7nqN92AVPhL0tESO7eMF
"""

!pip install torch torchvision transformers

import torch
import torchvision
import torchvision.transforms as transforms

transform = transforms.Compose(
    [transforms.Resize((224, 224)),
     transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=32,
                                         shuffle=False, num_workers=2)

from transformers import ViTForImageClassification, ViTFeatureExtractor

model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')
feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224')


model.config.num_labels = 10

import torch.optim as optim
import torch.nn as nn


optimizer = optim.Adam(model.parameters(), lr=0.0001)
criterion = nn.CrossEntropyLoss()


def train(model, trainloader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()

        outputs = model(inputs).logits
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        if i % 100 == 99:
            print(f'[{i + 1}] loss: {running_loss / 100:.3f}')
            running_loss = 0.0

    print('Finished Training')


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
train(model, trainloader, criterion, optimizer, device)

torch.save(model.state_dict(), 'vit_cifar10.pth')

def test(model, testloader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():  # Pas besoin de calculer les gradients lors de l'évaluation
        for data in testloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = model(images).logits
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f'Accuracy of the network on the test images: {100 * correct / total:.2f}%')


test(model, testloader, device)

import torch
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np


transform = transforms.Compose(
    [transforms.Resize((224, 224)),
     transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])


testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False, num_workers=2)

classes = ('plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')


def imshow(img):
    img = img / 2 + 0.5
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()

dataiter = iter(testloader)
images, labels = next(dataiter)

imshow(torchvision.utils.make_grid(images))

model.load_state_dict(torch.load('vit_cifar10.pth'))
model.to(device)

model.eval()


images = images.to(device)
outputs = model(images).logits
_, predicted = torch.max(outputs, 1)


print('Predicted: ', ' '.join(f'{classes[predicted[j]]}' for j in range(4)))
print('Actual: ', ' '.join(f'{classes[labels[j]]}' for j in range(4)))

test(model, testloader, device)

model.load_state_dict(torch.load('vit_cifar10.pth'))
model.to(device)

test(model, testloader, device)

import requests
from PIL import Image
from io import BytesIO
import torchvision.transforms as transforms
import torch

# on test avec une image de chien
url = 'https://i.f1g.fr/media/cms/704x396_cropupscale/2023/09/28/a2987bceb8ba1a60e5e6ee2c6f2176e4ffc009229c76318ea00607b45a1c1b98.jpg'  # Remplacez par l'URL de votre image
response = requests.get(url)
img = Image.open(BytesIO(response.content))

# Appliquer les mêmes transformations que celles utilisées pour l'entraînement
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

img = transform(img).unsqueeze(0)  # Ajouter une dimension batch

model.load_state_dict(torch.load('vit_cifar10.pth'))
model.to(device)

model.eval()

img = img.to(device)
outputs = model(img).logits
_, predicted = torch.max(outputs, 1)

print('Predicted class: ', classes[predicted[0]])